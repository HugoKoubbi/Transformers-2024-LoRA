<!-- Title -->
<h1 align="center">
  The impact of LoRA on the emergence of clusters in Transformers
</h1>

<p align="center">
  <a href=>
  </a>
</p>

<tt>Python</tt> codes for the paper 
**The impact of LoRA on the emergence of clusters in Transformers** by Hugo Koubbi, Matthieu Boussard and Louis Hernandez. 



<p align="center">
  <img src="" alt="animated" width="250"/>
  <img src=" alt="animated" width="250"/>
</p>


## Abstract

*In this paper, we employ the mathematical framework on Transformers developed by Sander et al.
(2022); Geshkovski et al. (2024); Geshkovski
et al. (2023) to explore how variations in atten-
tion parameters and initial token values impact the
structural dynamics of token clusters. Our analysis demonstrates that while the clusters within a
modified attention matrix dynamics can exhibit
significant divergence from the original over extended periods, they maintain close similarities
over shorter intervals, depending on the parameter differences. This work contributes to the
fine-tuning field through practical applications to
the LoRA algorithm (Hu et al., 2022; Mangrulkar
et al., 2022), enhancing our understanding of the
behavior of LoRA-enhanced Transformer models.*
