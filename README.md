<!-- Title -->
<h1 align="center">
  The impact of LoRA on the emergence of clusters in Transformers
</h1>

<p align="center">
  <a href=>
  </a>
</p>

<tt>Python</tt> codes for the paper 
**The impact of LoRA on the emergence of clusters in Transformers** by Hugo Koubbi, Matthieu Boussard and Louis Hernandez. 



<p align="center">
  <img src="" alt="animated" width="250"/>
  <img src=" alt="animated" width="250"/>
</p>


## Abstract

*In this paper, we employ the mathematical frame-
work on Transformers developed by Sander et al.
(2022); Geshkovski et al. (2024); Geshkovski
et al. (2023) to explore how variations in atten-
tion parameters and initial token values impact the
structural dynamics of token clusters. Our analy-
sis demonstrates that while the clusters within a
modified attention matrix dynamics can exhibit
significant divergence from the original over ex-
tended periods, they maintain close similarities
over shorter intervals, depending on the param-
eter differences. This work contributes to the
fine-tuning field through practical applications to
the LoRA algorithm (Hu et al., 2022; Mangrulkar
et al., 2022), enhancing our understanding of the
behavior of LoRA-enhanced Transformer models.*
